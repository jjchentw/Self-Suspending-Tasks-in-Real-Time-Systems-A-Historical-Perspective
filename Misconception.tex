
\section{Misconceptions in Some Existing Results}
\label{sec:misconceptions}

This section explains several misconceptions in some existing results by presenting concrete examples to demonstrate their overstatements. These examples are constructed case by case. Therefore, each misconception will be explained by using one specific example. 

\subsection{Incorrect Quantifications of Jitter - Dynamic Self-Suspension}
\label{sec:wrong-jitter-dynamic}

We first explain the existing misconceptions in the literature to quantify the jitter too optimistically for dynamic self-suspending task systems under fixed-priority scheduling. To calculate the worst-case response time of the task $\tau_k$ under analysis, there have been several results in the literature, i.e., \cite{ECRTS-AudsleyB04,RTAS-AudsleyB04,RTCSA-KimCPKH95,MingLiRTCSA1994},  which propose to calculate the worst-case response time $R_k$ of task $\tau_k$ by finding the minimum $R_k$ with
\begin{equation}
R_k = C_k+ S_k+\sum_{\tau_i \in hp(k)}\ceiling{\frac{R_k+S_k}{T_i}} C_i.
\label{eq:dynamic-flawed}
\end{equation}
The term $hp(k)$ is the set of the tasks with higher priority levels than task $\tau_k$. 
This analysis basically assumes that a safe estimate for $R_k$ can be computed if
every higher-priority task $\tau_i$ is modelled as an ordinary sporadic
task with worst-case execution time $C_i$ and release jitter $S_i$.
Intuitively, it represents the potential internal jitter, \textit{within} an activation of $\tau_i$, i.e., when its execution time $C_i$ is considered by disregarding any time intervals when $\tau_i$ is preempted. 
However, it is not the real jitter in the general cases, because the execution of $\tau_i$ can be pushed further, to be shown in the following example.


Consider the dynamic self-suspending task set presented in Table \ref{tab:counterexample-dynamic-suspension}. 
The analysis in Eq.~(\ref{eq:dynamic-flawed}) would yield $R_3=12$, as illustrated in 
Figure~\ref{fig:counterexample-dynamic}(a). However, the schedule of Figure~\ref{fig:counterexample-dynamic}(b), which is perfectly legal, 
disproves the claim that $R_3=12$, because $\tau_3$ in that case has a response time of $22-5\epsilon$ time units, 
where $\epsilon$ is an arbitrarily small quantity. 

\begin{table}[t]
\begin{center}
\begin{tabular}{|c|r|r|r|}
\hline
$\tau_i$ &      $C_i$   &   $S_i$  &     $T_i$     \\ \hline
$\tau_1$ &       $1$   &     $0$  &       $2$     \\ \hline
$\tau_2$  &      $5$   &     $5$  &      $20$     \\ \hline
$\tau_3$  &      $1$   &     $0$  &  $\infty$     \\ \hline
\end{tabular}
\end{center}
\caption{A set of tasks with dynamic self-suspensions for Section \ref{sec:wrong-jitter-dynamic}.}
\label{tab:counterexample-dynamic-suspension}
\end{table}


\begin{figure}[t]
\centering
\def\uxfpga{0.4cm} 
\subfloat[]{
\scalebox{0.8}{
	\begin{tikzpicture}[x=\uxfpga,y=\uy,auto, thick]
    \draw[->] (-6,0) -- coordinate (xaxis) (18,0) node[anchor=north]{$t$};
    \foreach \x in {-6,-4,...,16}{
		\draw[-,below](\x,0) -- (\x,-0.3) node[] {\pgfmathtruncatemacro\yi{\x} \yi};
	}
	\foreach \x in {-6,-5,...,16}{
         \draw[-,very thin,lightgray, dashed](\x,0.3) -- (\x,6);
	}	
	\foreach \y in {2.03,4.03}{
		\draw[] (-6,\y) -- (16,\y);
	}
	
	\begin{scope}[shift={(0,0)}]
		\node[anchor=east] at (-6, 0.5) {$\tau_3$};
        \draw[->] (0,0) -- (0,1.75);
        \draw[<-,thin,red] (0,1.3) -- (5.3,1.3);
        \draw[->,thin,red] (6.7,1.3) -- (12,1.3);
        \draw[<-,thin,red] (0,1.3) -- (5,1.3);
        \draw[] (12.05,0) -- (12.05,1.5);
        \node[anchor=east,red] at (6.7, 1.39) {$12$};
        \draw[dotted] (12.5,0.5) -- (13.3,0.5); 
        \node[task7, minimum width=\uxfpga, anchor=south west] at (11, 0){\footnotesize};         
	\end{scope}

	\begin{scope}[shift={(0,2)}]
		\node[anchor=east] at (-6, 0.5) {$\tau_2$};
        \draw[->] (-5,0) -- (-5,1.75);
        \draw[->] (15,0) -- (15,1.75);
        \draw[dotted] (15.5,0.5) -- (16.3,0.5); 
		\foreach \y in {0.3,0.5,0.7}{ 
        		\draw[] (-5,\y) -- (0,\y);
        	} 
        \draw[] (0,0) -- (0,1);
        \foreach \x in {1,3,...,9}{ 
        		\node[task7, minimum width=\uxfpga, anchor=south west] at (\x, 0){\footnotesize};
        	}
	\end{scope}

	\begin{scope}[shift={(0,4)}]
		\node[anchor=east] at (-6, 0.5) {$\tau_1$};
        \foreach \x in {0,2,...,14}{ 
			\draw[->] (\x,0) -- (\x,1.75);        		
        		\node[task7, minimum width=\uxfpga, anchor=south west] at (\x, 0){\footnotesize};
        	}
        \draw[dotted] (15.5,0.5) -- (16.3,0.5); 
	\end{scope}                
\end{tikzpicture}} }

\subfloat[]{
\scalebox{0.8}{
	\begin{tikzpicture}[x=\uxfpga,y=\uy,auto, thick]
    \draw[->] (0,0) -- coordinate (xaxis) (36,0) node[anchor=north]{$t$};
    \foreach \x in {0,2,...,34}{
		\draw[-,below](\x,0) -- (\x,-0.3) node[] {\pgfmathtruncatemacro\yi{\x} \yi};
	}
	\foreach \x in {0,1,...,34}{
         \draw[-,very thin,lightgray, dashed](\x,0.3) -- (\x,6);
	}	
	\foreach \y in {2.03,4.03}{
		\draw[] (0,\y) -- (34,\y);
	}
	
	\begin{scope}[shift={(0,0)}]
		\node[anchor=east] at (0, 0.5) {$\tau_3$};
        \draw[->] (10,0) -- (10,1.75);
        \draw[dotted] (32.5,0.5) -- (33.3,0.5); 
        \draw[<-,thin,red] (10,1.3) -- (19,1.3);
        \draw[->,thin,red] (22.4,1.3) -- (31.55,1.3);
        \node[anchor=east,red] at (22.3, 1.39) {$22-5\varepsilon$};
        \node[task7, minimum width=0.1*\uxfpga, anchor=south east] at (20, 0){\footnotesize}; 
        \draw[] (31,1) -- (31.55,1);
        \draw[] (31,0) -- (31.55,0);
        \draw[] (31,0) -- (31,1);
        \draw[] (31.55,0) -- (31.55,1.5);   
	\end{scope}

	\begin{scope}[shift={(0,2)}]
		\node[anchor=east] at (0, 0.5) {$\tau_2$};
        \draw[->] (0,0) -- (0,1.75);
        \draw[->] (20,0) -- (20,1.75);
        \draw[dotted] (35.2,0.5) -- (36,0.5); 
        \draw[<-] (1.2,1) --(1.8,1.38);
        \node[anchor=east] at (2.7, 1.5) {$\varepsilon$};
        \draw[<-] (19.85,1) --(19.1,1.39);
        \node[anchor=east] at (19.2, 1.5) {$5\varepsilon$};        
		\foreach \y in {0.3,0.5,0.7}{ 
			\foreach \x in {1.2,3.2,...,9.2}{        		
        			\draw[] (\x,\y) -- (\x+0.8,\y);
        	}} 
        	\foreach \x in {1,3,...,9}{
        		\draw[] (\x,0) -- (\x,1);
        		\draw[] (\x+0.2,0) -- (\x+0.2,1);
        		\draw[] (\x+1,0) -- (\x+1,1);
        		\draw[] (\x,0) -- (\x+0.2,0);
        		\draw[] (\x,1) -- (\x+0.2,1);
        	}
    		\foreach \x in {11,13,...,15}{
			\node[task7, minimum width=\uxfpga, anchor=south west] at (\x, 0){\footnotesize};
		}	
    		\foreach \x in {21,23,...,29}{
			\node[task7, minimum width=\uxfpga, anchor=south west] at (\x, 0){\footnotesize};
		}
		\foreach \y in {0.3,0.5,0.7}{ 
    			\draw[] (30,\y) -- (30,\y);
        	}
		\foreach \y in {0.3,0.5,0.7}{ 
    			\draw[] (19.4,\y) -- (20,\y);
        	}
        	\draw[] (19,1) -- (19.4,1);
        \draw[] (19,0) -- (19.4,0);
        \draw[] (19,0) -- (19,1);
        \draw[] (19.4,0) -- (19.4,1);				
	\end{scope}

	\begin{scope}[shift={(0,4)}]
		\node[anchor=east] at (0, 0.5) {$\tau_1$};
		\foreach \x in {0,2,...,32}{ 
    			\draw[->] (\x,0) -- (\x,1.75);
    			\node[task7, minimum width=\uxfpga, anchor=south west] at (\x, 0){\footnotesize};
        	}        
        \draw[->] (34,0) -- (34,1.75);
        \draw[dotted] (34.5,0.5) -- (35.3,0.5); 
	\end{scope}
\end{tikzpicture}} }
\caption{Two different schedules for the task set in Table~\ref{tab:counterexample-dynamic-suspension}.}
\label{fig:counterexample-dynamic}
\end{figure}

%\begin{figure}[t]
%\begin{center}
%\includegraphics[width=\linewidth]{../figures/CounterexampleDynamicSuspension/counterexample_classic.png}
%\end{center}
%\caption{Two different schedules for the task set in Table~\ref{tab:counterexample-dynamic-suspension}.}
%\label{fig:counterexample-dynamic}
%\end{figure}

{\bf Consequences:} Since the results in \cite{ECRTS-AudsleyB04,RTAS-AudsleyB04,RTCSA-KimCPKH95,MingLiRTCSA1994} are fully based on the analysis in Eq.~(\ref{eq:dynamic-flawed}), the above unsafe example disproves the correctness of their analyses. The source of error comes from a wrong interpretation by Ming \cite{MingLiRTCSA1994} in 1993 with respect to a paper by Audsley et al. \cite{audsley-1993}.\footnote{The technical report of \cite{audsley-1993} was referred in \cite{MingLiRTCSA1994}. Here we refer to the journal version.} Audsley et al. \cite{audsley-1993} explained that deferrable executions may result in arrival jitter and the jitter terms should be accounted while analyzing the worst-case response time. However, Ming \cite{MingLiRTCSA1994} interpreted that the jitter is the self-suspension time, which was not originally provided in \cite{audsley-1993}. Therefore, there was no proof of the correctness of the methods used in \cite{MingLiRTCSA1994}. The concept was adopted by Kim et al. \cite{RTCSA-KimCPKH95} in 1994. This misconception has become further prevailing since it was unfortunately applied in \cite{lakshmanan-2009} to analyze the worst-case response time for
partitioned multiprocessor real-time locking protocols. This has been then further reused in several other works~\cite{zeng-2011,bbb-2013,yang-2013,kim-2014,han-2014,carminati-2014,yang-2014}. Therefore, this misconception also causes analytical flaws in the above papers. We will explain such consequences in Section~\ref{sec:syn}. 
Moreover this counterexample also invalidates the comparison in \cite{RidouardR06}, which compares the schedulability tests from \cite{RTCSA-KimCPKH95} and \cite[Page 164-165]{Liu:2000:RS:518501}, since the result derived from \cite{RTCSA-KimCPKH95} is unsafe.

Independently, the authors of the results in \cite{ECRTS-AudsleyB04,RTAS-AudsleyB04} used the same methods in 2004 from different perspectives. They already filed a technical report \cite{BletsasReport2015} to explain in a great detail how to handle this. 

{\bf Solutions:} It is explained and proved in \cite{huangpass:dac2015,BletsasReport2015} that the worst-case response time of task $\tau_k$ is the minimum $R_k$ with
\begin{equation}
R_k = C_k+ S_k+\sum_{\tau_i \in hp(k)}\ceiling{\frac{R_k+D_i-C_i}{T_i}} C_i,
\label{eq:dynamic-correct}
\end{equation}
for \emph{constrained-deadline} task systems under the assumption that every higher priority task $\tau_i$ in $hp(k)$ can meet their relative deadline constraint. It is also safe to use $\ceiling{\frac{R_k+R_i-C_i}{T_i}}$ instead of $\ceiling{\frac{R_k+D_i-C_i}{T_i}}$ in the above equation if $R_i \leq T_i$.

\subsection{Incorrect Quantifications of Jitter - Segmented Self-Suspension}
\label{sec:wrong-jitter-segmented}


We now explain the existing misconception in the literature to quantify the jitter too optimistically for segmented self-suspending task systems by using fixed-priority scheduling.  The analysis in \cite{RTCSA-BletsasA05} adopts two steps: 
\begin{enumerate}
\item The computation segments and the self-suspension intervals (including a ``notional''
self-suspension corresponding to the interval between the completion of the task and its next arrival)
are reordered such that the computation segments appear with decreasing execution time and
the suspension intervals appear with increasing self-suspending time.
\item Each computation segment is modelled as a sporadic task with a fixed offset corresponding to the above
rearrangement and a fixed jitter term to represent all computation segments of a given task.
As reported in \cite{RTCSA-BletsasA05}, this jitter term corresponds to the maximum internal jitter, within the 
activation of the task, of any computation segment, due to variability in the length of 
preceding computation segments and self-suspending regions.
\end{enumerate}
The first step can be explained by using the following example of an
implicit-deadline segmented self-suspending task with $(C_i^1, S_i^1, C_i^2, S_i^2, C_i^3) = (1, 5, 4, 3, 2)$ and $T_i=40$.  It first artificially creates a notional gap $S_i^3=40-(1+5+4+3+2)=25$. After reordering, the task parameters become $(C_i^1, S_i^1, C_i^2, S_i^2, C_i^3, S_i^3)  = (4, 3, 2, 5, 1, 25)$.  The purpose of this reordering step was designed to avoid having to consider different release offsets for each interfering task (corresponding to its computational segments). 
%This is broadly analogous  to how Mok and Chen [REF] reorder task frames in their analysis for the multiframe task model.
The second step, which was designed to capture the effects of the variation in the length of 
computation segments or self-suspension intervals, would have no effect if 
there is no variation between the worst-case and the actual-case execution/suspension times.



Instead of going into the detailed mathematical formulations, we will demonstrate the above misconception with the following example listed in Table~\ref{tab:counterexample-segmented}, by assuming that there is no variation between the worst-case and the actual-case execution/suspension times.
In this example, there is only one self-suspending task $\tau_3$. In this specific example,  neither step 1 nor step 2 has any effect. The analysis in \cite{RTCSA-BletsasA05} is basically akin to replacing $\tau_3$ with a sporadic task without any jitter or self-suspension, with $C_3=2$ and $D_3=T_3=15$. Therefore, the analysis in \cite{RTCSA-BletsasA05}  concludes that the worst-case response time of task $\tau_4$ is at most $15$ since $C_4+\sum_{i=1}^{3}\ceiling{\frac{15}{T_i}} C_i = 3+ 6 + 4 + 2= 15$.


However, the schedule of Figure \ref{fig:counterexample-segmented} which is perfectly legal, disproves this.
In that schedule, $\tau_1$, $\tau_2$, and $\tau_3$ arrive at $t=0$ and a job of $\tau_4$ arrives at $t=40$ and has a response time of 
$18$ time units.

\begin{table}[t]
\begin{center}
\begin{tabular}{|c||c|r|r|r|}
\hline
$\tau_i$ & $(C_i^1, S_i^1, C_i^2)$   &   $D_i$  &     $T_i$     \\ \hline
$\tau_1$ &  $(2, 0, 0)$                    &     $5$  &       $5$     \\ \hline
$\tau_2$ &  $(2, 0, 0)$                    &    $10$  &      $10$     \\ \hline
$\tau_3$ &  $(1, 5, 1)$            &    $15$  &      $15$     \\ \hline
$\tau_4$ &  $(3, 0, 0)$                   &    $?$  &   $\infty$    \\ \hline     
\end{tabular}
\end{center}
\caption{A set of segmented self-suspending and sporadic real-time tasks for Section~\ref{sec:wrong-jitter-segmented}.}
\label{tab:counterexample-segmented}
\end{table}

\begin{figure}[t]
\centering
\def\uxfpga{0.25cm}
\scalebox{0.77}{
\begin{tikzpicture}[x=\uxfpga,y=\uy,auto, thick]
	\draw[->] (0,0) -- coordinate (xaxis) (62,0) node[anchor=north]{$t$};
	\foreach \x in {0,5,...,60}{
		\draw[-,below](\x,0) -- (\x,-0.3) node[] {\pgfmathtruncatemacro\yi{\x} \yi};
	}
	\foreach \x in {0,1,...,60}{
         \draw[-,very thin,lightgray, dashed](\x,0.3) -- (\x,8);
	}     
	\foreach \y in {2.03,4.03,6.03}{
		\draw[] (0,\y) -- (60,\y);
	}
       
	\begin{scope}[shift={(0,0)}]       
		\node[anchor=east] at (0, 0.5) {$\tau_4$};
		\draw[->] (40,0) -- (40,1.75);
		\draw[] (58.05,1) -- (58.05,1.5);
		\draw[dotted] (58.5,0.5) -- (60,0.5);
		\draw[<-,thin,red] (40,1.3) -- (48,1.3);
        	\draw[->,thin,red] (50,1.3) -- (58,1.3);
        	\node[anchor=east,red] at (50, 1.39) {18};
        	\node[task7, minimum width=2*\uxfpga, anchor=south west] at (48, 0){\footnotesize};         
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (57, 0){\footnotesize};
	\end{scope}
      
    \begin{scope}[shift={(0,2)}]  
		\node[anchor=east] at (0, 0.5) {$\tau_3$};
		\foreach \x in {0,15,...,60}{
			\draw[<-](\x,1.75) -- (\x,0);
		}		
    		\draw[dotted] (60.5,0.5) -- (62,0.5);         
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (4, 0){\footnotesize};
        	\foreach \y in {0.3,0.5,0.7}{ 
        		\draw[] (5,\y) -- (10,\y);
        	}
        	\draw[] (10,0) -- (10,1);
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (14, 0){\footnotesize};
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (17, 0){\footnotesize};
        	\foreach \y in {0.3,0.5,0.7}{ 
        	\draw[] (18,\y) -- (23,\y);}
        	\draw[] (23,0) -- (23,1);
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (24, 0){\footnotesize};
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (34, 0){\footnotesize};
        	\foreach \y in {0.3,0.5,0.7}{ 
        	\draw[] (35,\y) -- (40,\y);}
        	\draw[] (40,0) -- (40,1);
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (44, 0){\footnotesize};
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (47, 0){\footnotesize};
        	\foreach \y in {0.3,0.5,0.7}{ 
        		\draw[] (48,\y) -- (53,\y);
        	}
       	\draw[] (53,0) -- (53,1);
        	\node[task7, minimum width=\uxfpga, anchor=south west] at (54, 0){\footnotesize};
	\end{scope}
        
    \begin{scope}[shift={(0,4)}]        
		\node[anchor=east] at (0, 0.5) {$\tau_2$};
   		\foreach \x in {0,10,...,60}{
			\draw[<-](\x,1.75) -- (\x,0);
		}		
        	\draw[dotted] (60.5,0.5) -- (62,0.5);
        	\foreach \x in {2,12,...,52}{
			\node[task7, minimum width=2*\uxfpga, anchor=south west] at (\x, 0){\footnotesize};
		}
	\end{scope}

    \begin{scope}[shift={(0,6)}]        
		\node[anchor=east] at (0, 0.5) {$\tau_1$};
		\foreach \x in {0,5,...,55}{
			\draw[<-](\x,1.75) -- (\x,0);
			\node[task7, minimum width=2*\uxfpga, anchor=south west] at (\x, 0){\footnotesize};
		}
		\draw[<-](60,1.75) -- (60,0);		
		\draw[dotted] (60.5,0.5) -- (62,0.5);
	\end{scope}
\end{tikzpicture}}       
\caption{A schedule for the task set in Table  \ref{tab:counterexample-segmented}. }
\label{fig:counterexample-segmented}
\end{figure}

%\begin{figure}[t]
%\begin{center}
%\includegraphics[width=\linewidth]{../figures/CounterexampleSegmentedSuspension/counterexample_synthetic.png}
%\end{center}
%\caption{A schedule for the task set in Table  \ref{tab:counterexample-segmented}. }
%\label{fig:counterexample-segmented}
%\end{figure}

{\bf Consequences:} This example shows that the analysis in \cite{RTCSA-BletsasA05} is flawed.  The authors in \cite{RTCSA-BletsasA05}  already filed a technical report \cite{BletsasReport2015}.

{\bf Solutions:} There is no simple way to fix the error to exploit the information provided by the segmented self-suspending task model. However, quantifying the jitter of a self-suspending task $\tau_i$ with $D_i-C_i$ in Section~\ref{sec:wrong-jitter-dynamic}  remains safe for constrained-deadline task systems since the dynamic self-suspending pattern is more general than a segmented self-suspending pattern.

\subsection{Incorrect Assumptions in Critical Instant with Synchronous Releases}
\label{sec:wrong-critical}

Over the years, it has been well accepted that the characterization of the critical instant for self-suspending tasks is a complex problem. Nevertheless, although the complexity of verifying the existence of a feasible schedule for segmented self-suspending tasks has been proven to be ${\cal NP}$-hard in the strong sense \cite{Ridouard_2004}, the complexity of verifying the schedulability of a task set has only been studied for segmented self-suspending tasks with constrained deadlines scheduled with a fixed-priority scheduling algorithm (see Section~\ref{sec:hardness}), hence leaving hope for the existence of efficient schedulability tests for more constrained systems. 

Following that idea, Lakshmanan and Rajkumar \cite{LR:rtas10} proposed a pseudo-polynomial worst-case response time analysis for one segmented self-suspending (with one self-suspending interval) task $\tau_k$ assuming that 
\begin{itemize}
\item the scheduling algorithm is fixed priority;
\item $\tau_k$ is the lowest priority task;  and
\item all the higher priority tasks are sporadic and non-self-suspending.
\end{itemize}
The analysis, presented in \cite{LR:rtas10}, is based on the notion of critical instant, i.e., an instant at which, considering the state of the system, an execution request for $\tau_k$ will generate the largest response time. This critical instant was defined as follows:
\begin{itemize}
	\item every task releases a job simultaneously with $\tau_k$;
	\item the jobs of higher priority tasks that are eligible to be released during the self-suspension interval of $\tau_k$ are delayed to be aligned with the release of the subsequent computation segment of $\tau_k$; and
	\item all the remaining jobs of the higher priority tasks are released with their minimum inter-arrival time.
\end{itemize}

This definition of the critical instant is very similar to the definition of the critical instant of a non-self-suspending task. Specifically, it is based on the two intuitions that $\tau_k$ suffers the worst-case interference when (i) all higher priority tasks release their first jobs simultaneously with $\tau_k$ and (ii) they all release as many jobs as possible in each computation segment of $\tau_k$. Although intuitive, we provide examples that both statements are wrong, in which the examples already appeared in \cite{ecrts15nelissen}.

\subsubsection{A Counter-Example to the Synchronous Release}

\begin{table} 
\centering
    \begin{tabular}{|c|c|c|}
 \hline
        & $(C_i^1, S_i^1, C_i^2)$ &  $D_i=T_i$\\ 
        \hline
        $\tau_1$ & (1, 0, 0) &  4\\ 
        $\tau_2$ &  (1, 0, 0) & 50  \\ 
        $\tau_3$ & (1, 2, 3) & 100  \\
        \hline
    \end{tabular} 
    \caption{Task parameters for the counter example to the synchronous release of all tasks for Section~\ref{sec:wrong-critical}.}
    \label{table:ex-synch-releases}
\end{table}

\begin{figure}[t]
\centering
\def\uxfpga{0.4cm} 
\scalebox{1}{
	\begin{tikzpicture}[x=\uxfpga,y=\uy,auto, thick]
    \node[anchor=east] at (11.5, -1.75) {(a) Release jobs synchronously.};
    \node[anchor=east] at (28, -1.75) {(b) Do not release jobs synchronously.};
       
	\begin{scope}[shift={(0,0)}]       
    		\draw[->] (0,0) -- coordinate (xaxis) (12,0) node[anchor=north]{$t$};
    		\foreach \x in {0,2,...,10}{
			\draw[-,below](\x,0) -- (\x,-0.3) node[] {\pgfmathtruncatemacro\yi{\x} \yi};
		}
		\foreach \x in {0,1,...,10}{
        		\draw[-,very thin,lightgray, dashed](\x,0.3) -- (\x,6);
    		}
    		\foreach \y in {2.03,4.03}{
			\draw[] (0,\y) -- (10,\y);
		}		
		\node[anchor=east] at (0, 0.5) {$\tau_3$};
        \draw[->] (0,0) -- (0,1.75);
        \draw[dotted] (9.5,0.5) -- (10.3,0.5);
        \draw[<-,thin,red] (0,1.3) -- (3.9,1.3);
        \draw[->,thin,red] (5.1,1.3) -- (9,1.3);
        \draw[] (9.05,0) -- (9.05,1.5);
        \node[anchor=east,red] at (5, 1.39) {$9$}; 
        \node[task7, minimum width=\uxfpga, anchor=south west] at (2, 0){\footnotesize};     
        \node[task7, minimum width=3*\uxfpga, anchor=south west] at (6, 0){\footnotesize};    
		\foreach \y in {0.3,0.5,0.7}{        
			\draw[] (3,\y) -- (5,\y);
		}
		\draw[] (5,0) -- (5,1);
	\end{scope}
	
	\begin{scope}[shift={(0,2)}]       
		\node[anchor=east] at (0, 0.5) {$\tau_2$};
        \draw[->] (0,0) -- (0,1.75);
        \draw[dotted] (2.5,0.5) -- (3.3,0.5); 
        \node[task7, minimum width=\uxfpga, anchor=south west] at (1, 0){\footnotesize};
	\end{scope}	
        
    \begin{scope}[shift={(0,4)}]
    		\node[anchor=east] at (0, 0.5) {$\tau_1$};             
        \draw[->] (0,0) -- (0,1.75);
        \draw[dashed,->] (4,0) -- (4,1.75);
        \draw[->] (5,0) -- (5,1.75);
        \draw[->] (9,0) -- (9,1.75);
        \draw[dotted] (10.5,0.5) -- (11.3,0.5);
        \node[task7, minimum width=\uxfpga, anchor=south west] at (0, 0){\footnotesize};
        \node[task7, minimum width=\uxfpga, anchor=south west] at (5, 0){\footnotesize};
        \node[task7, minimum width=\uxfpga, anchor=south west] at (9, 0){\footnotesize};
	\end{scope}
	
	
	
	\begin{scope}[shift={(15,0)}]       
    		\draw[->] (0,0) -- coordinate (xaxis) (12,0) node[anchor=north]{$t$};
    		\foreach \x in {0,2,...,10}{
			\draw[-,below](\x,0) -- (\x,-0.3) node[] {\pgfmathtruncatemacro\yi{\x} \yi};
		}
		\foreach \x in {0,1,...,10}{
        		\draw[-,very thin,lightgray, dashed](\x,0.3) -- (\x,6);
    		}
    		\foreach \y in {2.03,4.03}{
			\draw[] (0,\y) -- (10,\y);
		}		
		\node[anchor=east] at (0, 0.5) {$\tau_3$};
        \draw[->] (0,0) -- (0,1.75);
        \draw[dotted] (10.5,0.5) -- (11.3,0.5); 
        \draw[<-,thin,red] (0,1.3) -- (4.3,1.3);
        \draw[->,thin,red] (5.7,1.3) -- (10,1.3);
        \draw[] (10.05,0) -- (10.05,1.5);
        \node[anchor=east,red] at (5.7, 1.39) {$10$}; 
        \node[task7, minimum width=\uxfpga, anchor=south west] at (1, 0){\footnotesize};     
        \node[task7, minimum width=2*\uxfpga, anchor=south west] at (6, 0){\footnotesize};
        \node[task7, minimum width=\uxfpga, anchor=south west] at (9, 0){\footnotesize};    
        \draw[] (4,0) -- (4,1);
		\foreach \y in {0.3,0.5,0.7}{        
			\draw[] (2,\y) -- (4,\y);
		}
	\end{scope}
	
	\begin{scope}[shift={(15,2)}]       
		\node[anchor=east] at (0, 0.5) {$\tau_2$};
        \draw[->] (4,0) -- (4,1.75);
        \draw[dotted] (6.5,0.5) -- (7.3,0.5); 
        \node[task7, minimum width=\uxfpga, anchor=south west] at (5, 0){\footnotesize};
	\end{scope}	
        
    \begin{scope}[shift={(15,4)}]             
        \node[anchor=east] at (0, 0.5) {$\tau_1$};
        \draw[dotted] (9.5,0.5) -- (10.3,0.5);
        \foreach \x in {0,4,8} {
			\draw[->] (\x,0) -- (\x,1.75);
			\node[task7, minimum width=\uxfpga, anchor=south west] at (\x, 0){\footnotesize};
        }
	\end{scope}	
\end{tikzpicture}}     
\caption{Counter example to the synchronous release of all tasks (by \cite{LR:rtas10}).}
\label{fig:ex-synch-releases}
\end{figure}

\ifpaper
%\begin{figure}[t]
%  \centering
%\captionsetup[subfigure]{width=\columnwidth}
%  \subfloat[all tasks release a job synchronously.]{\label{fig:ex-phi} }\includegraphics[width=0.85\linewidth]{../figures/ex-phi/ex-phi.pdf} \\
%  \subfloat[all tasks do not release a job synchronously.]{\label{fig:ex-no-phi} }\includegraphics[width=0.85\linewidth]{../figures/ex-no-phi/ex-no-phi}
%  \caption{Counter-example to the synchronous release of all tasks (by \cite{LR:rtas10}).}
%  \label{fig:ex-synch-releases}
%\end{figure}
\fi

Consider three implicit deadline tasks with the parameters presented in Table~\ref{table:ex-synch-releases}. Let us assume that the priorities of the tasks are assigned using the rate monotonic policy (i.e., the smaller the period, the higher the priority). We are interested in computing the worst-case response time of $\tau_3$. Following the definition of the critical instant presented in \cite{LR:rtas10}, all three tasks must release a job synchronously at time $0$. Using the standard response-time analysis for non-self-suspending tasks, we get that the worst-case response time of the first computation region of $\tau_3$ is equal to $R_3^1 = 3$. Because the second job of $\tau_1$ would be released in the self-suspending interval of $\tau_3$ if $\tau_1$ was strictly respecting its minimum inter-arrival time, the release of the second job of $\tau_1$ is delayed so as to coincide with the release of the second computation region of $\tau_3$ (see Figure~\ref{fig:ex-synch-releases}(a)). Considering the fact that the second job of $\tau_2$ cannot be released before time instant $50$ and hence does not interfere with the execution of $\tau_3$, the response time of the second computation segment of $\tau_3$ is thus equal to $R_3^2=4$. In total, the worst-case response time of $\tau_3$ when all tasks release a job synchronously is equal to 
$$R_3 = R_3^1 + S_3^1 + R_3^2 = 3 + 2 +4 = 9$$

Now, let us consider a job release pattern as shown in Figure~\ref{fig:ex-synch-releases}. Task $\tau_2$ does not release a job synchronously with task $\tau_3$ but with its second computation segment instead. The response time of the first computation segment of $\tau_3$ is thus reduced to $R_3^1=2$. However, both $\tau_1$ and $\tau_2$ can now release a job synchronously with the second computation segment of $\tau_3$, for which the response time is now equal to $R_3^2=6$ (see Figure~\ref{fig:ex-synch-releases}(b)). Thus, the total response time of $\tau_3$ in a scenario where not all higher priority tasks release a job synchronously with $\tau_3$ is equal to 
$$R_3 = R_3^1 + S_3^1 + R_3^2 = 2+2+6 = 10$$

{\bf Consequences:} To conclude, the synchronous release of all tasks does not necessarily generate the maximum interference for the self-suspending task $\tau_k$ and is thus not always a critical instant for $\tau_k$. 
It was however proven in \cite{ecrts15nelissen} that in the critical instant of a self-suspending task $\tau_k$, every higher priority task releases a job synchronously with the arrival of at least one computation segment of $\tau_k$, but not all higher priority tasks must release a job synchronously with the same computation segment.

{\bf Solutions:} The problem to define the critical instant remains open even for the special case defined above. The approach in \cite{ecrts15nelissen} is an exhaustive search.

\subsection{Counting Highest-Priority Self-Suspending Time to Reduce the Interference}
\label{sec:wrong-highest-priority}

We now present a misconception to handle the highest-priority segmented self-suspension task by using the self-suspension time to reduce its interference to the lower-priority sporadic task systems. 
We consider fixed-priority preemptive scheduling to schedule $n$ self-suspending sporadic real-time tasks on a single processor, in which $\tau_1$ is the highest priority task and $\tau_n$ is the lowest priority task. We focus on constrained-deadline task systems with $D_i \leq T_i$ or implicit-deadline systems with $D_i=T_i$ for $i=1,\ldots,n$.
Let us consider the simplest setting of such a case:
\begin{itemize}
\item there is only one self-suspending task, which is the highest-priority task, i.e., $\tau_1$,
\item the self-suspending time is fixed, i.e., early return of self-suspension has to be controlled, and
\item the actual execution time of the self-suspending task is always equal to its worst-case execution time.
\end{itemize}
Denote this task set as $\Gamma_{1s}$ (as also used in \cite{RTSS-KimANR13}).  Since $\tau_1$ is the highest-priority task, its execution behaviour is static under the above assumptions. The misconception here is to identify the critical instant  (Theorem 2 in \cite{RTSS-KimANR13}) as follows: ``a critical instant occurs when all the tasks are released at the same time if $C_1 +S_1 < C_i  \leq T_1-C_1-S_1 \mbox{ for } i \in\{i|i\in Z^{+} \mbox{ and } 1<i\leq n\}$ is satisfied.'' The misconception here is to use the self-suspension time (if it is long enough) to \emph{reduce} the computation demand of $\tau_i$ for interfering with lower-priority tasks. 


\begin{table} [t]
\centering
    \begin{tabular}{|c|c|c|}
 \hline
        & $(C_i^1, S_i^1, C_i^2)$ &  $D_i=T_i$\\ 
        \hline
        $\tau_1$ & $(\epsilon, 1, 1)$ &  $4+10\epsilon$\\ 
        $\tau_2$ &  ($2+2\epsilon$, 0, 0) & 6  \\ 
        $\tau_3$ & ($2+2\epsilon$, 0, 0) & 6  \\
        \hline
    \end{tabular} 
    \caption{Task parameters for the counterexample of Theorem 2 in \cite{RTSS-KimANR13}, $0 < \epsilon \leq 0.1$.}
    \label{table:ex-highest-priority}
\end{table}


{\it Counterexample of Theorem 2 in \cite{RTSS-KimANR13}:} Let $\epsilon$ be a positive and very small number, i.e., $0 < \epsilon \leq 0.1$. We have three tasks, listed in Table~\ref{table:ex-highest-priority}. It is clear that $2+\epsilon = C_1+S_1 < C_i = 2+2\epsilon \leq T_1-C_1-S_1 = 2+9\epsilon$ for $i=2,3$. The above theorem states that the worst case is to release all the three tasks together at time $0$ (as shown in Figure~\ref{fig:counterexample-reduce-interf}(a)). The analysis shows that the response time of task $\tau_3$ is at most $5+6\epsilon$. However, if we release task $\tau_1$ at time $0$ and release task $\tau_2$ and task $\tau_3$ at time $1+\epsilon$ (as shown in Figure~\ref{fig:counterexample-reduce-interf}(b)), the response time of the first job of task $\tau_3$ is $6+5\epsilon$. 

\begin{figure}[t]
\centering
\def\uxfpga{0.4cm} 
\scalebox{1}{
	\begin{tikzpicture}[x=\uxfpga,y=\uy,auto, thick]
    \node[anchor=east] at (11.5, -1.75) {(a) Release jobs synchronously.};
    \node[anchor=east] at (28, -1.75) {(b) Do not release jobs synchronously.};
       
	\begin{scope}[shift={(0,0)}]       
    		\draw[->] (0,0) -- coordinate (xaxis) (12,0) node[anchor=north]{$t$};
	    \foreach \x in {0,2,...,10}{
			\draw[-,below](\x,0) -- (\x,-0.3) node[] {\pgfmathtruncatemacro\yi{\x} \yi};
		}
		\foreach \x in {0,1,...,10}{
        		\draw[-,very thin,lightgray, dashed](\x,0.3) -- (\x,6);
    		}
    		\foreach \y in {2.03,4.03}{
			\draw[] (0,\y) -- (10,\y);
		}
		\node[anchor=east] at (0, 0.5) {$\tau_3$};
        \draw[->] (0,0) -- (0,1.75);
        \draw[->] (6,0) -- (6,1.75);       
        \draw[dotted] (6.5,0.5) -- (7.3,0.5);
        \draw[<-,thin,red] (0,1.3) -- (1.5,1.3);
        \draw[->,thin,red] (4.1,1.3) -- (5.6,1.3);
        \node[anchor=east,red] at (4.2, 1.39) {$5+6\varepsilon$};         
        \draw[] (3.3,1.03) -- (4.8,1.03);
        \draw[] (3.3,0) -- (3.3,1);
        \draw[] (4.8,0) -- (4.8,1);
        \draw[] (5,1.03) -- (5.6,1.03);
        \draw[] (5,0) -- (5,1);
        \draw[] (5.6,0) -- (5.6,1.5);
	\end{scope}
	
	\begin{scope}[shift={(0,2)}]       
        \node[anchor=east] at (0, 0.5) {$\tau_2$};
        \draw[->] (0,0) -- (0,1.75);
        \draw[->] (6,0) -- (6,1.75);
        \draw[dotted] (6.5,0.5) -- (7.3,0.5); 
        \node[task7, minimum width=\uxfpga, anchor=south west] at (0.2, 0){\footnotesize};
        \draw[] (2.2,0.03) -- (3.3,0.03);
        \draw[] (2.2,1.03) -- (3.3,1.03);
        \draw[] (2.2,0.03) -- (2.2,1.03);
        \draw[] (3.3,0.03) -- (3.3,1.03);
	\end{scope}	
        
    \begin{scope}[shift={(0,4)}]
    		\node[anchor=east] at (0, 0.5) {$\tau_1$};
    		\draw[dotted] (10.1,0.5) -- (11,0.5);    		
    		\foreach \x in {0,4.8}{
    			\draw[->] (\x,0) -- (\x,1.75);
    			\node[task7, minimum width=\uxfpga, anchor=south west] at (\x+1.2, 0){\footnotesize};
    			\draw[] (\x,1.03) -- (\x+0.2,1.03);
    			\draw[] (\x,0.03) -- (\x+0.2,0.03);
    			\draw[] (\x+0.2,0) -- (\x+0.2,1);
    			\foreach \y in {0.3,0.5,0.7}{
    			\draw[] (\x+0.2,\y) -- (\x+1.2,\y);
    		}}
    		\draw[->] (9.6,0) -- (9.6,1.75);
	\end{scope}
	
	
	
	
	\begin{scope}[shift={(15,0)}]       
    		\draw[->] (0,0) -- coordinate (xaxis) (12,0) node[anchor=north]{$t$};
	    \foreach \x in {0,2,...,10}{
			\draw[-,below](\x,0) -- (\x,-0.3) node[] {\pgfmathtruncatemacro\yi{\x} \yi};
		}
		\foreach \x in {0,1,...,10}{
        		\draw[-,very thin,lightgray, dashed](\x,0.3) -- (\x,6);
    		}
    		\foreach \y in {2.03,4.03}{
			\draw[] (0,\y) -- (10,\y);
		}
        \node[anchor=east] at (0, 0.5) {$\tau_3$};
        \draw[->] (1.2,0) -- (1.2,1.75);
        \draw[<-,red] (7.2,0) -- (8.6,1.3);
        \node[anchor=east,red] at (10.5, 1.68) {miss};
        \draw[<-,thin,red] (1.2,1.3) -- (3,1.3);
        \draw[->,thin,red] (5.7,1.3) -- (7.6,1.3);
        \node[anchor=east,red] at (5.8, 1.4) {$6+5\varepsilon$};
        \draw[] (4.25,1.03) -- (4.8,1.03);
        \draw[] (4.25,0.03) -- (4.8,0.03);
        \draw[] (4.25,0.03) -- (4.25,1.03);
        \draw[] (4.8,0.03) -- (4.8,1.03);
        \node[task7, minimum width=\uxfpga, anchor=south west] at (5, 0){\footnotesize};
        \draw[] (7,1.03) -- (7.6,1.03);
        \draw[] (7,0.03) -- (7,1.03);
        \draw[] (7.6,0.03) -- (7.6,1.5);
	\end{scope}
	
	\begin{scope}[shift={(15,2)}]       
		\node[anchor=east] at (0, 0.5) {$\tau_2$};
        \draw[->] (1.2,0) -- (1.2,1.75);
        \draw[->] (7.2,0) -- (7.2,1.75);
        \draw[] (2.2,1.03) -- (4.25,1.03);
        \draw[] (2.2,0.03) -- (4.25,0.03);
        \draw[] (2.2,0.03) -- (2.2,1.03);
        \draw[] (4.25,0.03) -- (4.25,1.03);
	\end{scope}	
        
    \begin{scope}[shift={(15,4)}]             
    		\node[anchor=east] at (0, 0.5) {$\tau_1$};
    		\foreach \x in {0,4.8}{
    			\draw[->] (\x,0) -- (\x,1.75);
    			\node[task7, minimum width=\uxfpga, anchor=south west] at (\x+1.2, 0){\footnotesize};
    			\draw[] (\x,1.03) -- (\x+0.2,1.03);
    			\draw[] (\x,0.03) -- (\x+0.2,0.03);
    			\draw[] (\x+0.2,0) -- (\x+0.2,1);
    			\foreach \y in {0.3,0.5,0.7}{
    			\draw[] (\x+0.2,\y) -- (\x+1.2,\y);
    		}}
    		\draw[->] (9.6,0) -- (9.6,1.75);
	\end{scope}	
 \end{tikzpicture}}     
  \caption{Counter example to the synchronous release of Theorem 2 in \cite{RTSS-KimANR13}.}
  \label{fig:counterexample-reduce-interf}
\end{figure}

This misconception also leads to a wrong statement in Theorem 3 in \cite{RTSS-KimANR13}:
\begin{quote}
{\it Theorem 3 in \cite{RTSS-KimANR13}}: For a taskset $\Gamma_{1s}$ with implicit deadlines, $\Gamma_{1s}$ is schedulable if the total utilization of the taskset is less than or equal to $n((2+2\gamma)^{\frac{1}{n}}-1)-\gamma$, where $n$ is the number of tasks in $\Gamma_{1s}$, and $\gamma$ is the ratio of
$S_1$ to $T_1$ and lies in the range of $0$ to $2^{\frac{1}{n-1}}-1$. 
\end{quote}


{\it Counterexample of Theorem 3 in \cite{RTSS-KimANR13}:} Suppose that the self-suspending task $\tau_1$ has two computation segments, with $C_1^1 = C_1-\epsilon$, $C_1^2 = \epsilon$, and $S_1=S_1^1 > 0$ with very small $0 < \epsilon \ll C_1^1$. For such an example, it is pretty obvious that this self-suspending highest-priority task is like an ordinary sporadic task, i.e., self-suspension does not matter. 
 In this counterexample, the utilization bound is still Liu and Layland bound $n(2^{\frac{1}{n}}-1)$ \cite{Liu_1973}, regardless of the ratio of $S_1/T_1$. 

The source of the error of Theorem 3 in \cite{RTSS-KimANR13} is due to its Theorem 2 and the footnote 4 in \cite{RTSS-KimANR13}, which claims that the case in Figure 7 in \cite{RTSS-KimANR13} is the worst case. This statement is incorrect and can be disproved by using the above counterexample. 


{\bf Consequences:} These examples show that Theorems 2 and 3 in \cite{RTSS-KimANR13} are flawed.  

{\bf Solutions:} The three assumptions, i.e., one highest-priority segmented self-suspending task, controlled suspension behaviour and controlled execution time  in \cite{RTSS-KimANR13} actually implies that the self-suspending behaviour of task $\tau_1$ can be modeled as several sporadic tasks with the same minimum inter-arrival time. That is, if the $j$-th computation segment of task $\tau_1$ starts its execution at time $t$, the earliest time for this computation segment to be executed again in the next job of task $\tau_1$ is at least $t+T_1$. Therefore, a constrained-deadline task $\tau_k$ can be feasibly scheduled by the fixed-priority scheduling strategy if $C_1+S_1 \leq D_1$ and for $2 \leq k \leq n$
  \begin{equation}
    \label{eq:tda-fixed}
\exists 0 < t \leq D_k, \qquad C_k + \sum_{i=1}^{k-1}\ceiling{\frac{t}{T_i}}C_i \leq t.    
  \end{equation}
This also implies that the utilization bound (for implicit-deadline task systems) is still Liu and Layland bound $n(2^{\frac{1}{n}}-1)$ \cite{Liu_1973}, regardless of the ratio of $S_1/T_1$. 

\subsection{Incorrect Segmented Fixed-Priority Scheduling with Periodic Enforcement}
\label{sec:wrong-periodic}

We now introduce misconceptions to adopt periodic enforcement for segmented self-suspending task systems. As mentioned in Section~\ref{sec:periodic-enforce}, we can set a constant offset to constrain the release time of a computation segment. If this offset is given, each computation segment behaves like a standard sporadic (or periodic) task. Therefore, the schedulability test for sporadic task systems can be directly applied. Since the offsets of two computation segments of a task may be different, one may want to assign each computation segment a \emph{fixed-priority} level.  However, this has to be carefully handled. 



Consider the example listed in Table~\ref{table:ex-periodic}. Suppose that the offset of the computation segment $C_2^1$ is $0$ and the offset of the computation segment $C_2^2$ is $10$. This setting creates three sporadic tasks.
Suppose that the segmented fixed priority assignment assigns $C_2^1$ the highest priority and $C_2^2$ the lowest priority. It should be clear that the worst-case response time of $C_2^1$ is $5$ and the worst-case response time of $C_1$ is $15$. We focus on the WCRT analysis of $C_2^2$.


Since the two computation segments of task $\tau_2$ should not have any overlap, one may think that during the analysis of the worst-case response time of $C_2^2$, we do not have to consider the computation segment $C_2^1$. The worst-case response time of $C_2^2$ (after its constant offset $10$) for this case is $26$ since $\ceiling{\frac{26}{30}} C_1 + C_2^2 = 26$. 
Since $26+10 < 40$, one may conclude that this enforcement results in a feasible schedule. This analysis is adopted in Section IV in \cite{RTSS-KimANR13} and Section 3 in \cite{DBLP:journals/ieicet/DingTT09}. 

Unfortunately, it is not. Figure~\ref{fig:counterexample-FP-segment-level} provides a concrete schedule, in which the response time of $C_2^2$ is larger than $30$, which implies a deadline miss. In fact, the $5$ units execution time of $C_2^1$ pushes $C_1$ and results in a deadline miss of task $\tau_2$.

\begin{table} [t]
\centering
    \begin{tabular}{|c|c|c|}
 \hline
        & $(C_i^1, S_i^1, C_i^2)$ &  $D_i=T_i$\\ 
        \hline
        $\tau_1$ & $(10, 0, 0)$ &  $30$\\ 
        $\tau_2$ &  $(5, 5, 16)$ & $40$  \\ 
        \hline
    \end{tabular} 
    \caption{Task parameters for the counterexample in Section~\ref{sec:wrong-periodic}.}
    \label{table:ex-periodic}
\end{table}


\begin{figure}[t]
\centering
\def\uxfpga{0.3cm}
\scalebox{0.91}{
\begin{tikzpicture}[x=\uxfpga,y=\uy,auto, thick]
    \draw[->] (0,0) -- coordinate (xaxis) (42,0) node[anchor=north]{$t$};
    \node[anchor=east] at (0, 0.5) {$\tau_2$};
    \node[anchor=east] at (0, 2.5) {$\tau_1$};

    \foreach \x in {0,5,...,40}{
		\draw[-,below](\x,0) -- (\x,-0.3) node[] {\pgfmathtruncatemacro\yi{\x} \yi};
    }
    \foreach \x in {0,1,...,40}{
		\draw[-,very thin,lightgray, dashed](\x,0.3) -- (\x,4);
    }     

	\begin{scope}[shift={(0,0)}]        
        \draw[] (0,2) -- (40,2);
        \draw[->] (0,0) -- (0,1.75);
        \draw[->] (10,0) -- (10,1.75);
        \foreach \y in {0.3,0.5,0.7}{
			\draw[] (5,\y) -- (10,\y);
		}
        \draw[<-,thin] (0,1.3) -- (3.3,1.3);
        \draw[->,thin] (6.6,1.3) -- (10,1.3);
        \node[anchor=east] at (6.6, 1.49) {offset};
        \draw[<-,red] (40,0) -- (40,1.2);
        \node[anchor=east,red] at (41.3, 1.49) {miss};
        \node[task7, minimum width=5*\uxfpga, anchor=south west] at (0, 0){\footnotesize $C_2^1$};         
        \node[task7, minimum width=15*\uxfpga, anchor=south west] at (15, 0){\footnotesize $C_2^2$};
	\end{scope}
	
	\begin{scope}[shift={(0,2)}]
        \draw[->] (0,0) -- (0,1.75);
        \draw[->] (30,0) -- (30,1.75);
        \node[task7, minimum width=10*\uxfpga, anchor=south west] at (5, 0){\footnotesize};         
        \node[task7, minimum width=10*\uxfpga, anchor=south west] at (30, 0){\footnotesize};
	\end{scope}
  \end{tikzpicture}}       
  \caption{A schedule to release the two tasks in Section~\ref{sec:wrong-periodic} simultaneously.}
  \label{fig:counterexample-FP-segment-level}
\end{figure}

%\begin{figure}[t]
%\begin{center}
%\input{../figures/CounterexampleFixedPrioritySegmented/carry-in-body.tex}
%\end{center}
%\caption{A schedule to release the two tasks in Section~\ref{sec:wrong-periodic} simultaneously at time $0$.}
%\label{fig:counterexample-FP-segment-level}
%\end{figure}

{\bf Consequences:} The priority assignment algorithms in \cite{RTSS-KimANR13,DBLP:journals/ieicet/DingTT09} use the above unsafe schedulability test to verify the priority assignments. Therefore, their results are flawed due to the unsafe schedulability test.

{\bf Solutions:} This requires us to revisit the schedulability test of a given segmented fixed-priority priority assignment. This can be observed as a reduction to 
the generalized multiframe (GMF) task model introduced by Baruah et al.~\cite{baruah1999generalized}. A GMF task $G_i$ consisting of $m_i$ frames is characterized by the $3$-tuple $(\vec{C_i},\vec{D_i},\vec{T_i})$, where $\vec{C_i}$,$\vec{D_i}$, and $\vec{T_i}$ are $m_i$-ary vectors $(C_{i}^0,C_{i}^1,...,C_{i}^{m_i-1})$ of execution requirements, $(D_{i}^0,D_{i}^1,...,D_{i}^{m_i-1})$ of relative deadlines, $(T_{i}^0,T_{i}^1,...,T_{i}^{m_i-1})$ of minimum inter-arrival times, respectively.
In fact, from the analysis perspective, a self-suspending task $\tau_i$ under the offset enforcement is equivalent to a GMF task $G_i$,  by considering the computation segments as the frames with different separation times \cite{WC16-suspend-DATE,DBLP:journals/ieicet/DingTT09}.

However, most of the existing fixed-priority scheduling results for the GMF task model assume a unique priority level \emph{per task}. To the best of our knowledge, the only results that can be applied for a unique level \emph{per computation segment} are the utilization-based analysis in \cite{DBLP:journals/corr/ChenHL15b,huang2015mode}. 

% \subsection{Incorrect Scheduling with Slack Enforcement}
% \label{sec:wrong-slack}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "JRTS/JRTS.tex"
%%% End:
