\section{Existing Solutions of Self-Suspending Tasks}

This section reviews existing solutions for scheduling and analyzing the schedulability of self-suspending task models. We will first explain the commonly adopted strategies in those solutions. Unfortunately, some of these concepts are incorrect. We will provide concrete reasons and some counterexamples to explain why such misconceptions may lead to over-optimistic analysis. At the end of this section, we will provide the rule of thumb when considering self-suspending task systems. 


\subsection{Common Strategies}

For self-suspending task systems, while executing, a job may suspend itself. While a job suspends, the scheduler removes the job from the ready queue. Such suspensions should be well characterized and the resulting workload interference should be well quantified to analyze the schedulability of the task systems. 

{\bf an example}

There are some common strategies to characterize and quantify the impact due to self-suspensions:
\begin{itemize}
\item {\bf Converting Higher-Priority to Self-Suspension:} In static-priority scheduling, we can convert the higher-priority self-suspending tasks into equivalent sporadic real-time tasks: When we are analyzing the schedulability of a task $\tau_k$, we can convert the higher-priority self-suspending tasks as sporadic tasks by treating the suspension as computation. That is, a higher-priority task $\tau_i$ (other than task $\tau_k$) has now worst-case execution time $C_i+S_i$. This simplifies the analysis. After converting, we only have one self-suspending task as the lowest-priority task in the system. For example, the analyses in \cite{LR:rtas10,ecrts15nelissen} are in this category.
\item {\bf Quantifications of Additional Higher-Priority Interferences due to Self-Suspensions:} Self-suspension may result in more workload from higher-priority jobs to interfere with a lower-priority job. One strategy is to convert the suspension time of a job of task $\tau_k$ under analysis into computation. Suppose that this job under analysis arrives at time $t_k$. The other higher-priority jobs except the job under analysis are considered to have self-suspensions. This is the completely opposite strategy to the first strategy above. Since a higher-priority self-suspending job may suspend itself before $t_k$ and resume after $t_k$, the self-suspending behaviour of a task can be considered to bring \emph{at most} one \emph{carry-in} job to be \emph{partially} executed after $t_k$. As we have converted task $\tau_k$'s self-suspension time as computation, the finishing time of the job of task $\tau_k$ is the earliest moment after $t_k$ such that the processor idles. 
\begin{itemize}
\item In the dynamic self-suspending task model, the above analysis implies that the higher-priority jobs arrived after time $t_k$ \emph{should not} suspend themselves to create the maximum interference. Therefore, suppose that the first arrival time of task $\tau_i$ after $t_k$ is $t_i$. Then, the demand of task $\tau_i$ released at time $t \geq t_i$ is $\ceiling{\frac{t-t_i}{T_i} } C_i$. So, we just have to account the demand of the carry-in job of task $\tau_i$ executed between $t_k$ and $t_1$. The workload of the carry-in job can be up to $C_i$, but can also be characterized in a more precise manner. The approaches in this category are presented in \cite{huangpass:dac2015,LiuChen:rtss2014} by greedily counting $C_i$ in the carry-in job. Another way to quantify the impact is to model the impact of the carry-in job by using the concept of \emph{jitter}. If the jitter of task $\tau_i$ to model self-suspension is $J_i$, then, the demand of task $\tau_i$ released at time $t+t_k$ is $\ceiling{\frac{t+J_i}{T_i} } C_i$. A safe way it to set $J_i$ to $T_i$, which can be imagined as a pessimistic analysis by assuming that the carry-in job of task $\tau_i$ has execution time $C_i$ and the release time $t_i$ is $t_k$. A more precise way to quantify the jitter is to use the worst-case response time of a higher-priority task $\tau_i$. That is, the jitter $J_i$ of task $\tau_i$ is $R_i-C_i$, where $R_i$ is the worst-case response time of a higher-priority task $\tau_i$ \cite{huangpass:dac2015}. One may quantify the jitter of task $\tau_i$ by setting $J_i$ to $S_i$, which has been adopted in \cite{DBLP:conf/ecrts/AudsleyB04}.
\end{itemize}
\end{itemize}


\subsection{Misconceptions in Some Existing Results}
\subsubsection{Incorrect Assumptions in Critical Instant Theorem with Synchronous Releases}
\subsubsection{Incorrect Quantifications of Additional Interferences due to Carry-In Jobs}
\subsubsection{Incorrect Quantifications of Jitter}
\subsection{Rule of Thumb When Considering Self-Suspending Systems}
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  